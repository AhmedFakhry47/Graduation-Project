{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from utils import model\n",
    "import time \n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(416,416,3), name='frame')\n",
    "out=model(inputs)\n",
    "yolo=tf.keras.models.Model(inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1=[238, 72, 58, 24, 203, 230, 54, 167, 246, 136, 106, 95, 226, 171, 43, 159, 231, 101, 65, 157]\n",
    "C2=[122, 71, 173, 32, 147, 241, 53, 197, 228, 164, 4, 209, 175, 223, 176, 182, 48, 3, 70, 13]\n",
    "C3=[148, 69, 133, 41, 157, 137, 125, 245, 89, 85, 162, 43, 16, 178, 197, 150, 13, 140, 177, 224]\n",
    "idx_to_labels=['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow','diningtable','dog','horse','motorbike','person','pottedplant','sheep','sofa','train','tvmonitor']\n",
    "def visualize_img(img,bboxes):\n",
    "  img=img.reshape(img.shape[1],img.shape[1],3)\n",
    "  for c, boxes_c in enumerate(bboxes):\n",
    "    for b in boxes_c:\n",
    "      ul_x, ul_y=b[0]-b[2]/2.0, b[1]-b[3]/2.0\n",
    "      br_x, br_y=b[0]+b[2]/2.0, b[1]+b[3]/2.0\n",
    "\n",
    "      ul_x, ul_y=(min(max(int(ul_x),0),415),min(max(int(ul_y),0),415))\n",
    "      br_x, br_y=(min(max(int(br_x),0),415),min(max(int(br_y),0),415))\n",
    "\n",
    "      color_class=(C1[c], C2[c], C3[c])\n",
    "      img=cv2.rectangle(img, (ul_x, ul_y), (br_x, br_y), color=color_class, thickness=3) \n",
    "      label = '%s: %.2f' % (idx_to_labels[c], b[-1]) \n",
    "      labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1) \n",
    "      ul_y = max(ul_y, labelSize[1]) \n",
    "      img=cv2.rectangle(img, (ul_x, ul_y - labelSize[1]), (ul_x + labelSize[0], ul_y + baseLine),color_class, cv2.FILLED) \n",
    "      img=cv2.putText(img, label, (ul_x, ul_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0)) \n",
    "\n",
    "  cv2.imshow('img', img)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second : 8.75718294285371\n",
      "Frames per second : 11.424389248723804\n",
      "Frames per second : 11.405079553229555\n",
      "Frames per second : 10.940151250583321\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "i=0\n",
    "t_diff=[]\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    i+=1\n",
    "    ts=time.time()\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (416,416), interpolation = cv2.INTER_AREA)\n",
    "    frame_resized= frame.reshape((1,416,416,3))\n",
    "    # Our operations on the frame come here\n",
    "    pred=yolo.predict(frame_resized)\n",
    "    boxes=out.get_boxes(pred, frame_resized.shape[:2])\n",
    "    visualize_img(frame,boxes)\n",
    "    # Display the resulting frame\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    t_diff.append(time.time()-ts)\n",
    "    \n",
    "    if i==100: \n",
    "        fps=1.0/np.mean(t_diff)\n",
    "        t_diff=[]\n",
    "        i=0\n",
    "    \n",
    "        print (\"Frames per second : {0}\".format(fps))\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ahmad\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from utils import model\n",
    "import time \n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensornets as nets\n",
    "C1=[238, 72, 58, 24, 203, 230, 54, 167, 246, 136, 106, 95, 226, 171, 43, 159, 231, 101, 65, 157]\n",
    "C2=[122, 71, 173, 32, 147, 241, 53, 197, 228, 164, 4, 209, 175, 223, 176, 182, 48, 3, 70, 13]\n",
    "C3=[148, 69, 133, 41, 157, 137, 125, 245, 89, 85, 162, 43, 16, 178, 197, 150, 13, 140, 177, 224]\n",
    "idx_to_labels=['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow','diningtable','dog','horse','motorbike','person','pottedplant','sheep','sofa','train','tvmonitor']\n",
    "def visualize_img(img,bboxes):\n",
    "  img=img.reshape(img.shape[1],img.shape[1],3)\n",
    "  for c, boxes_c in enumerate(bboxes):\n",
    "    for b in boxes_c:\n",
    "      ul_x, ul_y=b[0]-b[2]/2.0, b[1]-b[3]/2.0\n",
    "      br_x, br_y=b[0]+b[2]/2.0, b[1]+b[3]/2.0\n",
    "\n",
    "      ul_x, ul_y=(min(max(int(ul_x),0),415),min(max(int(ul_y),0),415))\n",
    "      br_x, br_y=(min(max(int(br_x),0),415),min(max(int(br_y),0),415))\n",
    "\n",
    "      color_class=(C1[c], C2[c], C3[c])\n",
    "      img=cv2.rectangle(img, (ul_x, ul_y), (br_x, br_y), color=color_class, thickness=3) \n",
    "      label = '%s: %.2f' % (idx_to_labels[c], b[-1]) \n",
    "      labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1) \n",
    "      ul_y = max(ul_y, labelSize[1]) \n",
    "      img=cv2.rectangle(img, (ul_x, ul_y - labelSize[1]), (ul_x + labelSize[0], ul_y + baseLine),color_class, cv2.FILLED) \n",
    "      img=cv2.putText(img, label, (ul_x, ul_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0)) \n",
    "\n",
    "  cv2.imshow('img', img)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ahmad\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensornets\\contrib_layers\\layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\ahmad\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensornets\\references\\yolo_utils.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 416, 416, 3))\n",
    "yolo=nets.TinyYOLOv2VOC(x, is_training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second : 3.3464474139197975\n",
      "Frames per second : 16.123566609644993\n",
      "Frames per second : 16.14641434301291\n",
      "Frames per second : 16.136469085550942\n",
      "Frames per second : 16.017199866342068\n",
      "Frames per second : 16.097848172293595\n",
      "Frames per second : 15.864979669030733\n",
      "Frames per second : 15.94075970419378\n",
      "Frames per second : 16.013750821342025\n",
      "Frames per second : 16.176966425392525\n",
      "Frames per second : 15.544528659490908\n",
      "Frames per second : 15.966981123097112\n",
      "Frames per second : 15.86509968869741\n",
      "Frames per second : 15.764095421114012\n",
      "Frames per second : 15.890530740871656\n",
      "Frames per second : 15.937077046420876\n",
      "Frames per second : 15.694848990124264\n",
      "Frames per second : 15.740077133547162\n",
      "Frames per second : 15.915983057574952\n",
      "Frames per second : 15.497300177278628\n",
      "Frames per second : 15.691648899176306\n",
      "Frames per second : 16.068135603089885\n",
      "Frames per second : 15.962666660577394\n",
      "Frames per second : 15.819401840635415\n",
      "Frames per second : 16.03802962958431\n",
      "Frames per second : 16.099176637082\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "i=0\n",
    "t_diff=[]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(yolo.pretrained())\n",
    "    while(True):\n",
    "    # Capture frame-by-frame\n",
    "        i+=1\n",
    "    # Our operations on the frame come here\n",
    "        ts=time.time()\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.resize(frame, (416,416), interpolation = cv2.INTER_AREA)\n",
    "        frame_resized= frame.reshape((1,416,416,3))\n",
    "        ylo = sess.run(yolo, {x: yolo.preprocess(frame_resized)})\n",
    "        boxes=yolo.get_boxes(ylo, frame_resized.shape[1:3])\n",
    "        visualize_img(frame,boxes)\n",
    "    # Display the resulting frame\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        t_diff.append(time.time()-ts)\n",
    "\n",
    "        if i==10: \n",
    "            fps=1.0/np.mean(t_diff)\n",
    "            t_diff=[]\n",
    "            i=0\n",
    "\n",
    "            print (\"Frames per second : {0}\".format(fps))\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
